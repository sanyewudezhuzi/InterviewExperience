# 集合面试题



# 一、数组

## 1. 什么是数组

>   一种用连续的内存空间存储相同数据类型的数据结构，通过索引来获取数组中的元素，索引从0开始，最后一个位置的索引为数组的长度减一



## 2. 操作平台如何根据索引获取对应元素的内存地址

>   拿int类型的数组举例，数组在内存中是连续存储的，JVM的栈中用一个变量存储数组的地址，由于int类型的数据大小占4个字节，因此索引为0的元素在内存中的地址从数组地址加0乘4个字节开始，到再往后推3个字节结束，索引为1就是从1×4+地址开始，到再往后推3个字节结束
>
>   **寻址公式：**
>
>   `a[i] = baseAddress + i * dataTypeSize`
>
>   baseAddress代表数组地址，i代表索引，dataTypeSize代表数组中元素类型的大小



## 3. 数组增删改查的时间复杂度

>   1.   数组通过索引查询，根据地址和寻址公式可以很快地找到元素，时间复杂度是O(1)
>   2.   由于数组是一段连续的内存空间，进行增、删会影响后面的所有元素，时间复杂度是O(n)



# 二、链表

## 1. 什么是链表

>   链表是一种非线性的数据结构，其中的每个元素称为结点，各结点间用指针连接起来。每个结点包含两个部分，一个是实际存储的元素，另一个是一个指针，用于指向下一个结点。



## 2. 单向链表、双向链表、循环链表、双向循环链表

>   1.   单链表是最基本的链表结构，结点中存储两个数据，一个是实际存储的元素，一个是指向下一个结点的指针
>   2.   双链表的结点中一共存储三个元素，除实际存储的数据外还有两个指针，一个指向上一个结点，一个指向下一个结点，因此给定一个结点，你既可以访问上一个结点的数据，也可以访问下一个结点的数据
>   3.   循环链表是单链表的进阶版，它的尾结点的指针会指向头结点的地址，因此实现循环
>   4.   双向循环链表是双链表的进阶版，它的头节点的上一个指针指向尾结点，尾结点的下一个指针指向头结点



## 3. 链表增删查的时间复杂度

>   1.   链表新增结点只需将新增结点指向下一个结点，再将上一个结点的指针指向它自己即可，时间复杂度是O(1)
>   2.   链表删除结点只需将待删除结点的上一个节点的指针指向待删除结点的下一个结点即可，时间复杂度是O(1)
>   3.   链表的查询需要从给定结点一次遍历判断，直到找到查询的结点，查询的时间复杂度是O(n)



## 4. 栈和队列

>   一句话概括：栈先进后出，队列先进先出



# 三、哈希表

## 1. 什么是哈希表

>   哈希表是一种根据键访问值的数据结构，它是由数组演变而来，根据数组通过索引访问数据的思想，将键进行哈希计算后得到的值作为索引访问数组中的值



## 2. 散列函数与散列冲突

>   将键进行哈希计算的函数称为散列函数，需要满足三个要求：
>
>   1.   计算后的值必须大于等于0
>   2.   键相同，哈希值一定相同
>   3.   键不同，哈希值一定不同
>
>   实际上，第1、2点必须实现，但第3点不可能实现，当有多个不同的键计算出的哈希值相同时，这种情况便称为散列冲突



## 3. 解释一下哈希冲突的链表法

>   在哈希表中，数组中的每个位置我们可以称之为桶或槽，每个槽中对应一条链表，所有哈希值相同的元素将存储到相同槽位的对应链表中。这样设计的哈希表进行插入操作时的时间复杂度为O(1)，进行查找与删除时的平均时间复杂度为O(1)，但如果散列函数设计得不好，则会导致散列冲突发生概率升高，这将会使时间复杂度急剧升高为O(n)。不过我们可以选择优化哈希表，将链表改造为如跳表、红黑树这类高效的动态数据结构，这样查询的时间复杂度为O(log(n))



# 四、二叉树

## 1. 满二叉树与完全二叉树

>   满二叉树
>
>   <img src="img/image-20231116200306091.png" alt="image-20231116200306091" style="zoom:25%;" />
>
>   1.   叶子节点全部都在最底层
>   2.   除叶子节点，每个节点都有左右两个子节点
>
>   
>
>   完全二叉树
>
>   <img src="img/image-20231116200236826.png" alt="image-20231116200236826" style="zoom: 25%;" />
>
>   1.   叶子节点在最底下两层
>   1.   除最后一层，其它层的节点数要达到最大
>   1.   最后一层的叶子节点靠左排序



## 2. 完全二叉树的数据结构

>   <img src="img/image-20231116200345805.png" alt="image-20231116200345805" style="zoom: 50%;" />
>
>   完全二叉树采用数组存储数据，当一个节点在数组的下标为k，则它的左子节点下标为2k，右子节点下标为2k+1。采用数组存储完全二叉树能够有效利用存储空间。



## 3. 二叉树遍历

>   <img src="img/image-20231116200710047.png" alt="image-20231116200710047" style="zoom:33%;" />
>
>   *   前序遍历：节点 -> 左 -> 右：3467589
>   *   中序遍历：左 -> 节点 -> 右：6473859
>   *   后序遍历：左 -> 右 -> 节点：6748953



## 4. 二叉搜索树

>   <img src="img/image-20231116200937251.png" alt="image-20231116200937251" style="zoom:50%;" />
>
>   1.   树中的任一节点的值，比其左节点大，比其右节点小
>   2.   任一节点的左、右子树也分别为二叉搜索树
>   3.   没有键值相等的节点



## 5. 红黑树的特质

>   1.   节点要么是红色，要么是黑色
>   2.   根节点是黑色
>   3.   叶子节点都是黑色的空节点
>   4.   红黑树中红色节点的子节点都是黑色
>   5.   从任一节点到叶子节点的所有路径都包含相同数目的黑色节点



# 五、集合

## 1. Collection和Map的集合分类

>   ![image-20231116201906490](img/image-20231116201906490.png)
>
>   *   Collection接口的子接口包括Set接口和List接口
>       *   List接口的实现类主要有ArrayList、LinkedList、Stack、Vector等
>           *   Stack是Java的栈实现，继承Vector类，性能不好，官方都不推荐用它
>           *   Vector相对来说是线程安全的，但不是绝对的，会有例外情况
>       *   Set接口的实现类主要有HashSet、LinkedHashSet、TreeSet等
>   *   Map接口的实现类有HashMap、LinkedHashMap、TreeMap、HashTable、ConcurrentHashMap、Properties等
>       *   HashTable是并发安全的Map，但是性能差
>       *   ConcurrentHashMap是并发安全的Map，性能较好



## 2. 数组和List的转换

>   *   数组 -> List：使用Arrays工具类的asList方法
>   *   List -> 数组：使用List的toArray方法，如果不传参则生成Object数组，传入参数对象并已初始化长度则返回该数组对象



## 3. List、Set、Map

>   *   List存储的数据的特点是有序、可重复、有索引，常用的实现类有ArrayList、LinkedList。ArrayList底层是动态数组，创建时数组的默认长度为0，添加第一个元素时长度会扩容为10，每次存满时长度会扩容1.5倍，如果一次添加多个元素扩容1.5倍还存不下，则会直接扩容到所需长度，是一种查询快、增删满的数据结构。LinkedList底层是双链表，是一种头尾增删快、查询较慢的数据结构。
>   *   Set中存储的数据的特点是无序、不可重复、无索引，常用的实现类有HashSet、LinkedHashSet、TreeSet。HashSet的底层是哈希表，在JDK8前是以数组+链表的方式实现的，在JDK8开始是以数组+链表+红黑树实现的。HashSet依靠hashcode和equals确定在数组中的位置，在新创建时数组的默认长度为16，默认的加载因子是0.75，当数组中的元素超过了数组长度与加载因子的乘积就会扩容两倍，当链表长度超过了8且数组的长度不少于64时，链表就会转换为红黑树，当红黑树的节点不大于6时又会退化为链表。LinkedHashSet底层就是比HashSet多了个双链表，因此实现了有序。而TreeSet的底层是红黑树，依靠比较来实现去重和排序。
>   *   Map的特点就是键唯一，对值不做要求。常用的实现类有HashMap、LinkedHashMap、TreeMap，这些类的底层与对应的Set集合的实现类基本类似。



## 4. HashMap的put()执行流程

>   1.   判断容器是否为空，是则扩容
>   2.   将key通过hashcode方法进行计算得到插入数组的索引
>   3.   找到数组中索引的位置，如果为空则直接插入
>   4.   如果不为空，如果是链表结构则会遍历链表并通过equals方法判断是否相同，相同则覆盖
>   5.   如果都不相同，则进行插入，在插入后判断链表长度是否大于8且数组长度不少于64，如果是就会将链表转化为红黑树，如果链表长度大于8且数组长度少于64则会扩容
>   6.   如果在插入元素时数组不为空且数据结构是红黑树，则直接插入，至于实现的是插入还是替换就交由红黑树判断
>   7.   最后在执行完插入操作后，会判断数组中的元素个数是否超过了数组长度与加载因子的乘积，如果是则扩容



## 5. HashMap的扩容机制

>   1.   初始化扩容
>   2.   元素个数大于阈值(数组长度与加载因子的乘积)扩容
>   3.   数组长度小于64时，链表长度大于8扩容
>   4.   数组长度大于64时，链表长度大于8不会扩容，会转换为红黑树



## 6. HashMap的数组索引计算公式

>   `index = (数组长度 - 1) & 哈希值`
>
>   <img src="img/image-20231116203602610.png" alt="image-20231116203602610" style="zoom:50%;" />
>
>   `哈希值 = (key == null) ? 0 : (key.hashCode()) ^ (h >> 16)`
>
>   <img src="img/image-20231116203622428.png" alt="image-20231116203622428" style="zoom:50%;" />
>
>   为什么要异或右移16位的结果？
>
>   使高位的特征也参与到运算，以这种方式来减少哈希冲突



## 7. 为什么HashMap的数组长度一定是2的幂次方？

>   1.   计算索引时效率更高，如果是2的幂次方可以使用位与运算代替取模
>   2.   扩容时重新计算索引效率更高：`hash & oldCap == 0`的元素留在原来位置，否则`新位置 = 旧位置 + oldCap`



## 8. 介绍一下ArrayList、LinkedList

>   ArrayList、LinkedList都是List接口的实现类。
>
>   ArrayList在集合的末尾增删元素耗时相等，但在其它位置进行增删操作耗时会比较高，因为它是基于动态数组实现的，在中间进行增删操作会对后续所有元素都造成影响，在进行增加操作时还可能涉及数组扩容导致数组重新分配。它的优势是查询很快，根据索引查询的时间复杂度是常量级的O(1)。
>
>   对于LinkedList来说，它的增删操作在任意位置耗时相同，它是基于双链表实现的数据结构，因此在链表的首尾进行增删操作比较快，但相对的，他的查询效率较差，时间的复杂度是O(n)。
>
>   对于两者的存储空间来说，ArrayList由于在底层数组的后面总会预留一定的容量空间，因此会造成一定的空间浪费；LinkedList虽然没有空间浪费，但是他每存储一个数据，就要多存储两个指针，一个指向上一个节点，一个指向下一个节点。总的来说，ArrayList适用于数据量小或者数据量大但增删少的场景，LinkedList适用于需要频繁对首尾进行增删操作的场景。



## 9. 多线程的情况下使用map集合如何保证线程安全（ConcurrentHashMap）

>   其实要使map能够并发安全的执行，利用同步代码块、同步方法、上Lock锁都可以实现，但执行的效率不高，因为在同一时刻只能有一个线程操作map。
>
>   然后我们的这种思想其实Java已经帮我们实现了，Java有个类叫HashTable，它几乎在所有的方法上都加上了同步锁，以此来保证线程安全。但HashTable的线程安全是以牺牲性能为代价的，因为每次操作都需要加锁，这会极大的影响程序的性能，不利于高并发场景的需求。因此它也被其它更优秀的集合类替代了，比如ConcurrentHashMap。
>
>   ConcurrentHashMap是一个支持高并发更新与查询的哈希表，是线程安全的。他继承了AbstractMap类，与HashMap是同级别的， 主要分为两个版本，一个是jdk7的版本，以分段锁来实现同步；一个是jdk8的版本，通过node节点+CAS算法+锁实现同步。
>
>   *   jdk7版本：可以理解为ConcurrentHashMap维护了一个长度为16的数组，这个数组的长度不会被改变，在数组中可以存储真正的HashMap结构。它是一种分段锁的思想：将维护的数组分为16段，每段分别上锁，这样可以减少锁的竞争，提高并发性，在最优的情况下可以让16个线程同时操作这个Map集合。
>   *   jdk8版本：思想是通过原子操作和局部加锁的方法保证了多线程的线程安全，从而尽可能减少了性能损耗
>       *   node是ConcurrentHashMap中的一个静态内部类，与HashMap里的node实现基本类似，也是最核心的内部类，所有插入ConcurrentHashMap的数据都包装在这里面。ConcurrentHashMap将node数组作为容器，Java官网称这个容器为bin，因为它是懒加载的，在首次使用时才初始化，并根据需要调整大小，容器的大小总是二的幂次方。ConcurrentHashMap会将每个bin中的第一个node上锁，每个bin的第一个node插入就需要用到CAS算法，其余的node插入、删除、替换操作就需要对bin中的第一个node加锁后再进行操作。
>       *   CAS的全称是Compare And Swap，即比较和交换，它的思想是乐观锁的思想，在操作数据时不对数据进行加锁，在提交的时候再验证是否存在冲突。它是一种原子操作，其中包含三个操作数，一个是需要更新的变量的内存位置，一般用V标识；一个是期望值，一般用E标识；一个是新值，一般用N标识。整个CAS算法的思路是线程根据V的内存位置获取具体的值，然后与期望值进行比较，如果比较结果相等，则将这个值修改为新值；如果比较结果不相等，那么就会认为有其它线程已经做了更新，此时他可以有两种策略，一种是重新获取V指向的值再次与期望值比较，重复执行比较交换操作，另一种就是直接结束线程。这个需要根据具体业务来做决策。
>           *   悲观锁：以一种预防的姿态在修改数据之前把数据锁住，然后再对数据进行读写，在它释放锁之前任何人都不能对其数据进行操作
>           *   乐观锁：操作数据时不会对操作的数据进行加锁，只有到数据提交的时候才来验证数据是否存在冲突，可以通过加版本号然后进行版本号的对比
>           *   原子操作是指一个独立而不可分割的操作，这个操作要么全部完成，要么全部不完成，不可能只完成一部分。在现代操作系统中，原子操作通常用于实现一些同步操作，从而实现数据的一致性和并发控制
>       *   此外，还有TreeNode、TreeBin等其它内部类，都是用于包装。
>       *   此外，ArrayList和HashSet也不是并发安全的，它们也有对应的用于并发场景的实现类，分别是CopyOnWriteArrayList、CopyOnWriteArraySet。
>   *   程序在运行时能够同时更新ConcurrentHashMap且不产生锁竞争的最大线程数默认是16，这个值可以在构造函数中设置。如果自己设置了并发度，ConcurrentHashMap会使用大于等于该值的最小的2的幂指数作为实际并发度，也就是比如你设置的值是17，那么实际并发度是32